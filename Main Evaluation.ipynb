{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "neural-advance",
   "metadata": {},
   "source": [
    "# Edges - Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intimate-special",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading austintexas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/data/dataset_versioning/plotting/plotting/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chicago\n",
      "Reading gov.maryland\n",
      "Reading oregon\n",
      "Reading utah\n",
      "Reading education\n",
      "Reading football\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/data/dataset_versioning/plotting/plotting/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "/home/leon/data/dataset_versioning/plotting/plotting/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading military\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/data/dataset_versioning/plotting/plotting/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading politics\n",
      "Reading tv_and_film\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/data/dataset_versioning/plotting/plotting/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "/home/leon/data/dataset_versioning/plotting/plotting/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComponentID        object\n",
      "Method             object\n",
      "cliqueID            int64\n",
      "cliqueSize          int64\n",
      "vertex1ID          object\n",
      "vertex2ID          object\n",
      "remainsValid         bool\n",
      "evidence            int64\n",
      "score             float64\n",
      "edgeID             object\n",
      "edgeIDIsSorted       bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from plotnine import *\n",
    "from plotnine.data import *\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix, precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "#### REPLACE THIS WITH THE PATH TO YOUR DATA ########################\n",
    "pathToData = 'data/cliqueData/' \n",
    "#####################################################################\n",
    "#####################################################################\n",
    "\n",
    "def prepareDF(df):\n",
    "    df['edgeID'] = df['vertex1ID'] + '_' + df['vertex2ID']\n",
    "    df['edgeIDIsSorted'] = df['vertex1ID'] > df['vertex2ID']\n",
    "    filtered=df[df['evidence']>0]\n",
    "    return filtered[filtered['cliqueSize']>1]\n",
    "\n",
    "def readDF(weightedConfig,unweightedConfig,datasetName):\n",
    "    maxRecallConfig = 'max_recall'\n",
    "    pathMaxRecall=pathToData + datasetName + '/' + maxRecallConfig + '/edges.csv'\n",
    "    pathWeighted=pathToData + datasetName + '/' + weightedConfig +'/edges.csv'\n",
    "    pathUnweighted=pathToData + datasetName + '/' + unweightedConfig +'/edges.csv'\n",
    "    dfEdgesMaxRecall = prepareDF(pd.read_csv(pathMaxRecall))\n",
    "    dfEdgesWeighted = prepareDF(pd.read_csv(pathWeighted))\n",
    "    dfEdgesUnweighted = prepareDF(pd.read_csv(pathUnweighted))\n",
    "    datasetResult = {'maxRecall':dfEdgesMaxRecall,weightedConfig:dfEdgesWeighted,unweightedConfig:dfEdgesUnweighted}\n",
    "    allDfs[datasetName] = datasetResult\n",
    "\n",
    "weightedConfigSocrata = \"alpha_3.1E-5\"\n",
    "unweightedConfigSocrata = \"baselineNoWeight\"\n",
    "datasetNamesSocrata = [\"austintexas\",\"chicago\", \"gov.maryland\",  \"oregon\",  \"utah\"]\n",
    "weightedConfigWikipedia = \"alpha_5.18E-4\"\n",
    "unweightedConfigWikipedia = \"baselineNoWeight\"\n",
    "datasetNamesWikipedia = [\"education\",\"football\",\"military\", \"politics\", \"tv_and_film\"]\n",
    "\n",
    "allDfs = {}\n",
    "\n",
    "for datasetName in datasetNamesSocrata:\n",
    "    print(\"Reading\",datasetName)\n",
    "    readDF(weightedConfigSocrata,unweightedConfigSocrata,datasetName)\n",
    "    \n",
    "for datasetName in datasetNamesWikipedia:\n",
    "    print(\"Reading\",datasetName)\n",
    "    readDF(weightedConfigWikipedia,unweightedConfigWikipedia,datasetName)\n",
    "    \n",
    "print(allDfs[datasetNamesSocrata[0]][\"maxRecall\"].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-conviction",
   "metadata": {},
   "source": [
    "# Precision Recall and F1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "presidential-avenue",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset,unweighted,unweighted,unweighted,weighted,weighted,weighted\n",
      ",precision,recall,f1,precision,recall,f1\n",
      "chicago,0.85,0.87,0.86,0.9,0.8,0.85\n",
      "austintexas,0.83,0.22,0.35,0.94,0.6,0.73\n",
      "gov.maryland,0.23,0.17,0.2,0.25,0.17,0.2\n",
      "oregon,0.57,0.34,0.43,0.35,0.85,0.5\n",
      "utah,0.91,0.98,0.94,0.93,0.93,0.93\n",
      "politics,0.53,0.5,0.51,0.57,0.66,0.61\n",
      "military,0.53,0.27,0.36,0.61,0.58,0.59\n",
      "tv_and_film,0.72,0.39,0.51,0.72,0.52,0.6\n",
      "education,0.79,0.94,0.86,0.79,0.91,0.85\n",
      "football,0.68,0.57,0.62,0.69,0.53,0.6\n"
     ]
    }
   ],
   "source": [
    "def getPrecision(df,filterByInteresting):\n",
    "    dfToUse=df\n",
    "    if(filterByInteresting):\n",
    "        dfToUse=df[df['evidence']>0]\n",
    "    truth=dfToUse['remainsValid']\n",
    "    dfToUse['predicted']=True\n",
    "    predicted=dfToUse['predicted']\n",
    "    return accuracy_score(truth, predicted)\n",
    "\n",
    "def printSingleCSVString(dsName,configName,newline):\n",
    "    dfMaxRecall=allDfs[dsName]['maxRecall']\n",
    "    dfConfigResult=allDfs[dsName][configName]\n",
    "    dfConfigResult=dfConfigResult[dfConfigResult['evidence']>0]\n",
    "    validEdgesFromMaxRecall = dfMaxRecall[dfMaxRecall['remainsValid']]\n",
    "    validEdgesFromConfig = dfConfigResult[dfConfigResult['remainsValid']]\n",
    "    allPositives = set(validEdgesFromMaxRecall['edgeID'])\n",
    "    truePositives = set(validEdgesFromConfig['edgeID'])\n",
    "    recall = round(len(allPositives.intersection(truePositives)) / len(allPositives),2)\n",
    "    precision = round(getPrecision(dfConfigResult,True),2)\n",
    "    f1 = round(2*recall*precision/(recall+precision),2)\n",
    "    if(newline):\n",
    "        print(precision,recall,f1,sep=\",\")\n",
    "    else:\n",
    "        print(dsName,precision,recall,str(f1) + \",\",sep=\",\",end=\"\")\n",
    "\n",
    "def printCSVString(dsName,weightedConfigName,unweightedConfigName):\n",
    "    printSingleCSVString(dsName,unweightedConfigName,False)\n",
    "    printSingleCSVString(dsName,weightedConfigName,True)\n",
    "\n",
    "print(\"Dataset\",\"unweighted\",\"unweighted\",\"unweighted\",\"weighted\",\"weighted\",\"weighted\",sep=\",\")\n",
    "\n",
    "print(\"\",\"precision\",\"recall\",\"f1\",\"precision\",\"recall\",\"f1\",sep=\",\")\n",
    "\n",
    "for datasetName in datasetNamesSocrata:\n",
    "    printCSVString(datasetName,weightedConfigSocrata,unweightedConfigSocrata)\n",
    "for datasetName in datasetNamesWikipedia:\n",
    "    printCSVString(datasetName,weightedConfigWikipedia,unweightedConfigSocrata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-morning",
   "metadata": {},
   "source": [
    "# Exporting Role Matchings for Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ordinary-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intersting failures (edges labelled as invalid sorted descendingly by score)\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "#### REPLACE THIS WITH THE PATH TO YOUR Output Dir ########################\n",
    "exportPath = 'exportedData/' \n",
    "###########################################################################\n",
    "###########################################################################\n",
    "\n",
    "for dsName in datasetNamesWikipedia:\n",
    "    df = allDfs[dsName][weightedConfigWikipedia]\n",
    "    invalid = df[df['remainsValid']==False]\n",
    "    invalid = invalid.sort_values('score',ascending=False)\n",
    "    invalid.to_csv( exportPath + \"invalidEdges_\"+dsName+\".csv\")\n",
    "    \n",
    "for dsName in datasetNamesSocrata:\n",
    "    df = allDfs[dsName][weightedConfigSocrata]\n",
    "    invalid = df[df['remainsValid']==False]\n",
    "    invalid = invalid.sort_values('score',ascending=False)\n",
    "    invalid.to_csv(exportPath + \"invalidEdges_\"+dsName+\".csv\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "popular-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting max recall edge set:\n",
    "\n",
    "def exportEdgeIDs(configName,datasetName):\n",
    "    ds = allDfs[datasetName][configName]\n",
    "    path = exportPath + 'maxRecallEdges_' + datasetName + \".csv\"\n",
    "    ds['edgeID'].to_csv(path)\n",
    "\n",
    "for datasetName in datasetNamesSocrata:\n",
    "    exportEdgeIDs(unweightedConfigSocrata,datasetName) #does not matter which config we pass here, max recall is the same for both\n",
    "    \n",
    "for datasetName in datasetNamesWikipedia:\n",
    "    exportEdgeIDs(unweightedConfigWikipedia,datasetName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nasty-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting all true positive edges\n",
    "def exportTruePositiveEdgeIDs(configName,datasetName):\n",
    "    ds = allDfs[datasetName][configName]\n",
    "    ds = ds[ds['remainsValid']]\n",
    "    path = exportPath + 'truePositiveEdges_' + datasetName + \".csv\"\n",
    "    ds[['vertex1ID','vertex2ID']].to_csv(path)\n",
    "\n",
    "for datasetName in datasetNamesSocrata:\n",
    "    exportTruePositiveEdgeIDs(weightedConfigSocrata,datasetName)\n",
    "    \n",
    "for datasetName in datasetNamesWikipedia:\n",
    "    exportTruePositiveEdgeIDs(weightedConfigWikipedia,datasetName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-electric",
   "metadata": {},
   "source": [
    "# Clique Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "enormous-bullet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chicago\n",
      "Reading austintexas\n",
      "Reading gov.maryland\n",
      "Reading oregon\n",
      "Reading utah\n",
      "Reading politics\n",
      "Reading military\n",
      "Reading tv_and_film\n",
      "Reading education\n",
      "Reading football\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/data/dataset_versioning/plotting/plotting/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "/home/leon/data/dataset_versioning/plotting/plotting/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComponentID                        object\n",
      "Method                             object\n",
      "cliqueID                            int64\n",
      "cliqueSize                          int64\n",
      "edgesTotal                          int64\n",
      "validEdges                          int64\n",
      "totalEvidence                       int64\n",
      "fractionOfVerticesWithEvidence    float64\n",
      "score                             float64\n",
      "alpha                             float64\n",
      "remainsValid                         bool\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/data/dataset_versioning/plotting/plotting/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "#header: ComponentID,Method,cliqueID,cliqueSize,edgesTotal,validEdges,totalEvidence,fractionOfVerticesWithEvidence,score,alpha\n",
    "\n",
    "def readCliqueDF(weightedConfig,unweightedConfig,datasetName):\n",
    "    pathWeighted='data/cliqueData/' +datasetName + '/' + weightedConfig +'/cliques.csv'\n",
    "    weightedDF = pd.read_csv(pathWeighted)\n",
    "    weightedDF['remainsValid'] = (weightedDF['validEdges'] == weightedDF['edgesTotal'])\n",
    "    weightedDF = weightedDF[weightedDF['cliqueSize']>1]\n",
    "    \n",
    "    pathUnweighted='data/cliqueData/' +datasetName + '/' + unweightedConfig +'/cliques.csv'\n",
    "    unweightedDF = pd.read_csv(pathUnweighted)\n",
    "    unweightedDF['remainsValid'] = (unweightedDF['validEdges'] == unweightedDF['edgesTotal'])\n",
    "    unweightedDF = unweightedDF[unweightedDF['cliqueSize']>1]\n",
    "    \n",
    "    datasetResult = {weightedConfig:weightedDF,unweightedConfig:unweightedDF}\n",
    "    allCliqueDfs[datasetName] = datasetResult\n",
    "\n",
    "weightedConfigSocrata = \"alpha_3.1E-5\"\n",
    "unweightedConfigSocrata = \"baselineNoWeight\"\n",
    "datasetNamesSocrata = [\"chicago\", \"austintexas\", \"gov.maryland\",  \"oregon\",  \"utah\"]\n",
    "weightedConfigWikipedia = \"alpha_5.18E-4\"\n",
    "unweightedConfigWikipedia = \"baselineNoWeight\"\n",
    "datasetNamesWikipedia = [\"politics\",\"military\", \"tv_and_film\",\"education\",\"football\"]\n",
    "\n",
    "\n",
    "allCliqueDfs = {}\n",
    "\n",
    "for datasetName in datasetNamesSocrata:\n",
    "    print(\"Reading\",datasetName)\n",
    "    readCliqueDF(weightedConfigSocrata,unweightedConfigSocrata,datasetName)\n",
    "    \n",
    "for datasetName in datasetNamesWikipedia:\n",
    "    print(\"Reading\",datasetName)\n",
    "    readCliqueDF(weightedConfigWikipedia,unweightedConfigWikipedia,datasetName)\n",
    "    \n",
    "print(allCliqueDfs['chicago'][weightedConfigSocrata].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "seventh-spanish",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------Weighted-----------------------------------------------\n",
      "Dataset,CliquePrecision\n",
      "chicago,0.9\n",
      "austintexas,0.89\n",
      "gov.maryland,0.24\n",
      "oregon,0.72\n",
      "utah,0.93\n",
      "politics,0.37\n",
      "military,0.33\n",
      "tv_and_film,0.45\n",
      "education,0.36\n",
      "football,0.43\n",
      "---------------------------------Unweighted-----------------------------------------------\n",
      "Dataset,CliquePrecision\n",
      "chicago,0.87\n",
      "austintexas,0.85\n",
      "gov.maryland,0.26\n",
      "oregon,0.67\n",
      "utah,0.91\n",
      "politics,0.33\n",
      "military,0.3\n",
      "tv_and_film,0.42\n",
      "education,0.31\n",
      "football,0.36\n"
     ]
    }
   ],
   "source": [
    "def printPrecision(dsName,configName,datasource):\n",
    "    df=allCliqueDfs[dsName][configName]\n",
    "    df=df[df['totalEvidence']>0]\n",
    "    validEdgesFromConfig = df[df['remainsValid']]\n",
    "    precision = len(validEdgesFromConfig.index) / len(df.index)\n",
    "    weightedPrecision = sum(validEdgesFromConfig['edgesTotal']) / sum(df['edgesTotal'])\n",
    "    print(dsName,round(precision,2),sep=\",\")\n",
    "    resultRow = {'datasource':datasource,'dataset':dsName,'configName':configName,'Precision':precision}\n",
    "    resultDFRows.append(resultRow)\n",
    "\n",
    "resultDFRows=[]\n",
    "\n",
    "print(\"---------------------------------Weighted-----------------------------------------------\")\n",
    "print(\"Dataset\",\"CliquePrecision\",sep=\",\")\n",
    "for datasetName in datasetNamesSocrata:\n",
    "    printPrecision(datasetName,weightedConfigSocrata,\"socrata\")\n",
    "\n",
    "for datasetName in datasetNamesWikipedia:\n",
    "    printPrecision(datasetName,weightedConfigWikipedia,\"wikipedia\")\n",
    "\n",
    "print(\"---------------------------------Unweighted-----------------------------------------------\")\n",
    "print(\"Dataset\",\"CliquePrecision\",sep=\",\")\n",
    "for datasetName in datasetNamesSocrata:\n",
    "    printPrecision(datasetName,unweightedConfigSocrata,\"socrata\")\n",
    "\n",
    "for datasetName in datasetNamesWikipedia:\n",
    "    printPrecision(datasetName,unweightedConfigWikipedia,\"wikipedia\")\n",
    "\n",
    "resultCliqueDF = pd.DataFrame(resultDFRows)\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
