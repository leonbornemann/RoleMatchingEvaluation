{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "neural-advance",
   "metadata": {},
   "source": [
    "# Edges - Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-special",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading austintexas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/data/dataset_versioning/plotting/plotting/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chicago\n",
      "Reading gov.maryland\n",
      "Reading oregon\n",
      "Reading utah\n",
      "Reading education\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from plotnine import *\n",
    "from plotnine.data import *\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix, precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "def prepareDF(df):\n",
    "    df['edgeID'] = df['vertex1ID'] + '_' + df['vertex2ID']\n",
    "    df['edgeIDIsSorted'] = df['vertex1ID'] > df['vertex2ID']\n",
    "    filtered=df[df['evidence']>0]\n",
    "    return filtered[filtered['cliqueSize']>1]\n",
    "\n",
    "def readDF(weightedConfig,unweightedConfig,datasetName):\n",
    "    maxRecallConfig = 'max_recall'\n",
    "    pathMaxRecall='data/cliqueData/' + datasetName + '/' + maxRecallConfig + '/edges.csv'\n",
    "    pathWeighted='data/cliqueData/' +datasetName + '/' + weightedConfig +'/edges.csv'\n",
    "    pathUnweighted='data/cliqueData/' +datasetName + '/' + unweightedConfig +'/edges.csv'\n",
    "    dfEdgesMaxRecall = prepareDF(pd.read_csv(pathMaxRecall))\n",
    "    dfEdgesWeighted = prepareDF(pd.read_csv(pathWeighted))\n",
    "    dfEdgesUnweighted = prepareDF(pd.read_csv(pathUnweighted))\n",
    "    datasetResult = {'maxRecall':dfEdgesMaxRecall,weightedConfig:dfEdgesWeighted,unweightedConfig:dfEdgesUnweighted}\n",
    "    allDfs[datasetName] = datasetResult\n",
    "\n",
    "weightedConfigSocrata = \"alpha_3.1E-5\"\n",
    "unweightedConfigSocrata = \"baselineNoWeight\"\n",
    "datasetNamesSocrata = [\"austintexas\",\"chicago\", \"gov.maryland\",  \"oregon\",  \"utah\"]\n",
    "weightedConfigWikipedia = \"alpha_5.18E-4\"\n",
    "unweightedConfigWikipedia = \"baselineNoWeight\"\n",
    "datasetNamesWikipedia = [\"education\",\"football\",\"military\", \"politics\", \"tv_and_film\"]\n",
    "\n",
    "allDfs = {}\n",
    "\n",
    "for datasetName in datasetNamesSocrata:\n",
    "    print(\"Reading\",datasetName)\n",
    "    readDF(weightedConfigSocrata,unweightedConfigSocrata,datasetName)\n",
    "    \n",
    "for datasetName in datasetNamesWikipedia:\n",
    "    print(\"Reading\",datasetName)\n",
    "    readDF(weightedConfigWikipedia,unweightedConfigWikipedia,datasetName)\n",
    "    \n",
    "print(allDfs[datasetNamesSocrata[0]][\"maxRecall\"].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-conviction",
   "metadata": {},
   "source": [
    "# Precision Recall and F1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "presidential-avenue",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austintexas,0.83,0.22,0.35,0.94,0.6,0.73\n",
      "chicago,0.85,0.87,0.86,0.9,0.8,0.85\n",
      "gov.maryland,0.23,0.17,0.2,0.25,0.17,0.2\n",
      "oregon,0.57,0.34,0.43,0.35,0.85,0.5\n",
      "utah,0.91,0.98,0.94,0.93,0.93,0.93\n",
      "education,0.79,0.94,0.86,0.79,0.91,0.85\n",
      "football,0.68,0.57,0.62,0.69,0.53,0.6\n",
      "military,0.53,0.27,0.36,0.61,0.58,0.59\n",
      "politics,0.53,0.5,0.51,0.57,0.66,0.61\n",
      "tv_and_film,0.72,0.39,0.51,0.72,0.52,0.6\n"
     ]
    }
   ],
   "source": [
    "def getPrecision(df,filterByInteresting):\n",
    "    dfToUse=df\n",
    "    if(filterByInteresting):\n",
    "        dfToUse=df[df['evidence']>0]\n",
    "    truth=dfToUse['remainsValid']\n",
    "    dfToUse['predicted']=True\n",
    "    predicted=dfToUse['predicted']\n",
    "    return accuracy_score(truth, predicted)\n",
    "\n",
    "def getNumCorrectReturnedAllEdges(df,filterByInteresting):\n",
    "    dfToUse=df\n",
    "    if(filterByInteresting):\n",
    "        dfToUse=df[df['evidence']>0]\n",
    "    numCorrect=len(dfToUse[dfToUse['remainsValid']].index)\n",
    "    return numCorrect\n",
    "\n",
    "def getValidEdgeSet(df):\n",
    "    return set(df['vertex1ID'] + '_' + df['vertex2ID'])\n",
    "\n",
    "def printSingleCSVString(dsName,configName,newline):\n",
    "    dfMaxRecall=allDfs[dsName]['maxRecall']\n",
    "    dfConfigResult=allDfs[dsName][configName]\n",
    "    dfConfigResult=dfConfigResult[dfConfigResult['evidence']>0]\n",
    "    validEdgesFromMaxRecall = dfMaxRecall[dfMaxRecall['remainsValid']]\n",
    "    validEdgesFromConfig = dfConfigResult[dfConfigResult['remainsValid']]\n",
    "    allPositives = set(validEdgesFromMaxRecall['edgeID'])\n",
    "    truePositives = set(validEdgesFromConfig['edgeID'])\n",
    "    recall = round(len(allPositives.intersection(truePositives)) / len(allPositives),2)\n",
    "    precision = round(getPrecision(dfConfigResult,True),2)\n",
    "    f1 = round(2*recall*precision/(recall+precision),2)\n",
    "    if(newline):\n",
    "        print(precision,recall,f1,sep=\",\")\n",
    "    else:\n",
    "        print(dsName,precision,recall,str(f1) + \",\",sep=\",\",end=\"\")\n",
    "\n",
    "def printCSVString(dsName,configName,configNameBaseline):\n",
    "    #print(configName,configNameBaseline)\n",
    "    printSingleCSVString(dsName,configNameBaseline,False)\n",
    "    printSingleCSVString(dsName,configName,True)\n",
    "\n",
    "def processDS(dsName,configName):\n",
    "    print(\"--------------------------------------------------------------------------------\")\n",
    "    print(dsName,configName)\n",
    "    dfMaxRecall=allDfs[dsName]['maxRecall']\n",
    "    dfConfigResult=allDfs[dsName][configName]\n",
    "    dfConfigResult=dfConfigResult[dfConfigResult['evidence']>0]\n",
    "    validEdgesFromMaxRecall = dfMaxRecall[dfMaxRecall['remainsValid']]\n",
    "    validEdgesFromConfig = dfConfigResult[dfConfigResult['remainsValid']]\n",
    "    allPositives = set(validEdgesFromMaxRecall['edgeID'])\n",
    "    truePositives = set(validEdgesFromConfig['edgeID'])\n",
    "    recall = len(allPositives.intersection(truePositives)) / len(allPositives)\n",
    "    precision = getPrecision(dfConfigResult,True)\n",
    "    f1 = 2*recall*precision/(recall+precision)\n",
    "    print(\"Precision\",precision)\n",
    "    print(\"Recall\",recall)\n",
    "    print(\"F-Measure\",f1)\n",
    "\n",
    "for datasetName in datasetNamesSocrata:\n",
    "    printCSVString(datasetName,configNameSocrataOurApproach,configNameSocrataBaselineNoWeight)\n",
    "for datasetName in datasetNamesWikipedia:\n",
    "    printCSVString(datasetName,configNameWikipediaOurApproach,configNameWikipediaBaselineNoWeight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-morning",
   "metadata": {},
   "source": [
    "# Exporting Role Matchings for Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ordinary-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intersting failures (edges labelled as invalid sorted descendingly by score)\n",
    "\n",
    "for dsName in datasetNamesWikipedia:\n",
    "    chicagoResult = allDfs[dsName][configNameWikipediaOurApproach]\n",
    "    chicagoInvalid = chicagoResult[chicagoResult['remainsValid']==False]\n",
    "    chicagoInvalid = chicagoInvalid.sort_values('score',ascending=False)\n",
    "    chicagoInvalid.to_csv(\"exportedData/invalidEdges/\"+dsName+\".csv\")\n",
    "    chicagoInvalid\n",
    "    \n",
    "for dsName in datasetNamesSocrata:\n",
    "    chicagoResult = allDfs[dsName][configNameSocrataOurApproach]\n",
    "    chicagoInvalid = chicagoResult[chicagoResult['remainsValid']==False]\n",
    "    chicagoInvalid = chicagoInvalid.sort_values('score',ascending=False)\n",
    "    chicagoInvalid.to_csv(\"exportedData/invalidEdges/\"+dsName+\".csv\")\n",
    "    chicagoInvalid    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sustainable-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting max recall edge set:\n",
    "\n",
    "def exportEdgeIDs(configName,datasetName):\n",
    "    ds = allDfs[datasetName][configName]\n",
    "    path = 'exportedData/maxRecallEdges/' + datasetName + \".csv\"\n",
    "    ds['edgeID'].to_csv(path)\n",
    "\n",
    "for datasetName in datasetNamesSocrata:\n",
    "    exportEdgeIDs(configNameSocrataBaselineNoWeight,datasetName)\n",
    "    \n",
    "for datasetName in datasetNamesWikipedia:\n",
    "    exportEdgeIDs(configNameWikipediaBaselineNoWeight,datasetName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "optimum-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting all true positive edges\n",
    "def exportTruePositiveEdgeIDs(configName,datasetName):\n",
    "    ds = allDfs[datasetName][configName]\n",
    "    ds = ds[ds['remainsValid']]\n",
    "    path = 'exportedData/truePositiveEdges/' + datasetName + \".csv\"\n",
    "    ds[['vertex1ID','vertex2ID']].to_csv(path)\n",
    "\n",
    "for datasetName in datasetNamesSocrata:\n",
    "    exportTruePositiveEdgeIDs(configNameSocrataOurApproach,datasetName)\n",
    "    \n",
    "for datasetName in datasetNamesWikipedia:\n",
    "    exportTruePositiveEdgeIDs(configNameWikipediaOurApproach,datasetName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-electric",
   "metadata": {},
   "source": [
    "# Clique Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "enormous-bullet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chicago\n",
      "Dataset chicago has  20317 cliques and 23297  edges of which  21025 are valid\n",
      "Reading austintexas\n",
      "Dataset austintexas has  27076 cliques and 81834  edges of which  76675 are valid\n",
      "Reading gov.maryland\n",
      "Dataset gov.maryland has  1292 cliques and 2420  edges of which  606 are valid\n",
      "Reading oregon\n",
      "Dataset oregon has  4741 cliques and 38381  edges of which  14296 are valid\n",
      "Reading utah\n",
      "Dataset utah has  13106 cliques and 22172  edges of which  21729 are valid\n",
      "Reading politics\n",
      "Dataset politics has  10853 cliques and 69428  edges of which  45764 are valid\n",
      "Reading military\n",
      "Dataset military has  16449 cliques and 141711  edges of which  93018 are valid\n",
      "Reading tv_and_film\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/data/dataset_versioning/plotting/plotting/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset tv_and_film has  50704 cliques and 584225  edges of which  477343 are valid\n",
      "Reading education\n",
      "Dataset education has  19213 cliques and 1545031  edges of which  1307725 are valid\n",
      "Reading football\n",
      "Dataset football has  83985 cliques and 819385  edges of which  603066 are valid\n",
      "ComponentID                        object\n",
      "Method                             object\n",
      "cliqueID                            int64\n",
      "cliqueSize                          int64\n",
      "edgesTotal                          int64\n",
      "validEdges                          int64\n",
      "totalEvidence                       int64\n",
      "fractionOfVerticesWithEvidence    float64\n",
      "score                             float64\n",
      "alpha                             float64\n",
      "remainsValid                         bool\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/data/dataset_versioning/plotting/plotting/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "/home/leon/data/dataset_versioning/plotting/plotting/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "#header: ComponentID,Method,cliqueID,cliqueSize,edgesTotal,validEdges,totalEvidence,fractionOfVerticesWithEvidence,score,alpha\n",
    "\n",
    "def readCliqueDF(configName,baselineConfigName,datasetName):\n",
    "    pathConfig='data/cliqueData/' +datasetName + '/' + configName +'/cliques.csv'\n",
    "    cliqueDF = pd.read_csv(pathConfig)\n",
    "    cliqueDF['remainsValid'] = (cliqueDF['validEdges'] == cliqueDF['edgesTotal'])\n",
    "    cliqueDF = cliqueDF[cliqueDF['cliqueSize']>1]\n",
    "    \n",
    "    pathConfigBaseline='data/cliqueData/' +datasetName + '/' + baselineConfigName +'/cliques.csv'\n",
    "    baselineDF = pd.read_csv(pathConfigBaseline)\n",
    "    baselineDF['remainsValid'] = (baselineDF['validEdges'] == baselineDF['edgesTotal'])\n",
    "    baselineDF = baselineDF[baselineDF['cliqueSize']>1]\n",
    "    \n",
    "    datasetResult = {configName:cliqueDF,baselineConfigName:baselineDF}\n",
    "    print(\"Dataset\",datasetName,\"has \",len(cliqueDF.index),\"cliques and\", sum(cliqueDF.edgesTotal),\" edges of which \",sum(cliqueDF.validEdges),\"are valid\")\n",
    "    allCliqueDfs[datasetName] = datasetResult\n",
    "\n",
    "configNameSocrata = \"alpha_3.1E-5\"\n",
    "configNameSocrataBaseline = \"baselineNoWeight\"\n",
    "datasetNamesSocrata = [\"chicago\", \"austintexas\", \"gov.maryland\",  \"oregon\",  \"utah\"]\n",
    "configNameWikipedia = \"alpha_5.18E-4\"\n",
    "configNameWikipediaBaseline = \"baselineNoWeight\"\n",
    "datasetNamesWikipedia = [\"politics\",\"military\", \"tv_and_film\",\"education\",\"football\"]\n",
    "\n",
    "\n",
    "allCliqueDfs = {}\n",
    "\n",
    "for datasetName in datasetNamesSocrata:\n",
    "    print(\"Reading\",datasetName)\n",
    "    readCliqueDF(configNameSocrata,configNameSocrataBaseline,datasetName)\n",
    "    \n",
    "for datasetName in datasetNamesWikipedia:\n",
    "    print(\"Reading\",datasetName)\n",
    "    readCliqueDF(configNameWikipedia,configNameWikipediaBaseline,datasetName)\n",
    "    \n",
    "print(allCliqueDfs['chicago'][configNameSocrata].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seventh-spanish",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "0.89\n",
      "0.24\n",
      "0.72\n",
      "0.93\n",
      "0.37\n",
      "0.33\n",
      "0.45\n",
      "0.36\n",
      "0.43\n",
      "--------------------------------------------------------------------------------\n",
      "0.87\n",
      "0.85\n",
      "0.26\n",
      "0.67\n",
      "0.91\n",
      "0.33\n",
      "0.3\n",
      "0.42\n",
      "0.31\n",
      "0.36\n"
     ]
    }
   ],
   "source": [
    "def processCliqueDS(dsName,configName,datasource):\n",
    "    #print(\"--------------------------------------------------------------------------------\")\n",
    "    #print(dsName,configName)\n",
    "    dfConfigResult=allCliqueDfs[dsName][configName]\n",
    "    dfConfigResult=dfConfigResult[dfConfigResult['totalEvidence']>0]\n",
    "    #print(dfMaxRecall)\n",
    "    #print(dfConfigResult)\n",
    "    validEdgesFromConfig = dfConfigResult[dfConfigResult['remainsValid']]\n",
    "    precision = len(validEdgesFromConfig.index) / len(dfConfigResult.index)\n",
    "    weightedPrecision = sum(validEdgesFromConfig['edgesTotal']) / sum(dfConfigResult['edgesTotal']) \n",
    "    #print(\"Precision\",precision)\n",
    "    #print(\"Weighted Precision\",weightedPrecision)\n",
    "    #print(\"Rounded Precision &\",round(precision,2))\n",
    "    print(round(precision,2))\n",
    "    resultRow = {'datasource':datasource,'dataset':dsName,'configName':configName,'Precision':precision}\n",
    "    resultDFRows.append(resultRow)\n",
    "\n",
    "resultDFRows=[]\n",
    "for datasetName in datasetNamesSocrata:\n",
    "    processCliqueDS(datasetName,configNameSocrata,\"socrata\")\n",
    "    \n",
    "for datasetName in datasetNamesWikipedia:\n",
    "    processCliqueDS(datasetName,configNameWikipedia,\"wikipedia\")\n",
    "    \n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "    \n",
    "for datasetName in datasetNamesSocrata:\n",
    "    processCliqueDS(datasetName,configNameSocrataBaseline,\"socrata\")\n",
    "    \n",
    "for datasetName in datasetNamesWikipedia:\n",
    "    processCliqueDS(datasetName,configNameWikipediaBaseline,\"wikipedia\")\n",
    "    \n",
    "resultCliqueDF = pd.DataFrame(resultDFRows)\n",
    "\n",
    "#plot = (ggplot(resultCliqueDF, aes(x='dataset',ymin=0,ymax=1, y='Precision',fill='dataset')) \n",
    "#      + geom_col(show_legend=False)\n",
    "#      #+ geom_point(size=3)\n",
    "#      #+ scale_x_continuous(name=\"Matching Time [%]\")\n",
    "#      #+ scale_y_continuous(name=\"Validity\")\n",
    "#      + theme(text=element_text(size=14),axis_text_x=element_text(rotation=45, hjust=1))\n",
    "#      #+ theme(axis_text_x=element_text(size=12),axis_text_y=element_text(size=12))\n",
    "#      + labs(title='',x=''))\n",
    "#print(plot)\n",
    "#fname = 'exportedPlots/cliquePrecision.jpg'\n",
    "#plot.save(filename = fname)\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
